{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNhty7rj6i0Oe+7CByBl4No",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emaantech99/Auto-Tagging-Support-Tickets-Using-LLM/blob/main/Task_2_End_to_End_ML_Pipeline_with_Scikit_learn_Pipeline_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mnpvs1Lpe0ki",
        "outputId": "7f230e41-3210-46b5-df4c-1a42caac033f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Initial Data Overview ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7043 entries, 0 to 7042\n",
            "Data columns (total 21 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   customerID        7043 non-null   object \n",
            " 1   gender            7043 non-null   object \n",
            " 2   SeniorCitizen     7043 non-null   int64  \n",
            " 3   Partner           7043 non-null   object \n",
            " 4   Dependents        7043 non-null   object \n",
            " 5   tenure            7043 non-null   int64  \n",
            " 6   PhoneService      7043 non-null   object \n",
            " 7   MultipleLines     7043 non-null   object \n",
            " 8   InternetService   7043 non-null   object \n",
            " 9   OnlineSecurity    7043 non-null   object \n",
            " 10  OnlineBackup      7043 non-null   object \n",
            " 11  DeviceProtection  7043 non-null   object \n",
            " 12  TechSupport       7043 non-null   object \n",
            " 13  StreamingTV       7043 non-null   object \n",
            " 14  StreamingMovies   7043 non-null   object \n",
            " 15  Contract          7043 non-null   object \n",
            " 16  PaperlessBilling  7043 non-null   object \n",
            " 17  PaymentMethod     7043 non-null   object \n",
            " 18  MonthlyCharges    7043 non-null   float64\n",
            " 19  TotalCharges      7043 non-null   object \n",
            " 20  Churn             7043 non-null   object \n",
            "dtypes: float64(1), int64(2), object(18)\n",
            "memory usage: 1.1+ MB\n",
            "None\n",
            "\n",
            "--- First 5 Rows of the Dataset ---\n",
            "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
            "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
            "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
            "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
            "3  7795-CFOCW    Male              0      No         No      45           No   \n",
            "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
            "\n",
            "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
            "0  No phone service             DSL             No  ...               No   \n",
            "1                No             DSL            Yes  ...              Yes   \n",
            "2                No             DSL            Yes  ...               No   \n",
            "3  No phone service             DSL            Yes  ...              Yes   \n",
            "4                No     Fiber optic             No  ...               No   \n",
            "\n",
            "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
            "0          No          No              No  Month-to-month              Yes   \n",
            "1          No          No              No        One year               No   \n",
            "2          No          No              No  Month-to-month              Yes   \n",
            "3         Yes          No              No        One year               No   \n",
            "4          No          No              No  Month-to-month              Yes   \n",
            "\n",
            "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
            "0           Electronic check          29.85         29.85    No  \n",
            "1               Mailed check          56.95        1889.5    No  \n",
            "2               Mailed check          53.85        108.15   Yes  \n",
            "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
            "4           Electronic check          70.70        151.65   Yes  \n",
            "\n",
            "[5 rows x 21 columns]\n",
            "\n",
            "--- Starting Data Cleaning and Preprocessing ---\n",
            "\n",
            "Missing values in TotalCharges after conversion: 11\n",
            "\n",
            "Training set shape: (5634, 19)\n",
            "Testing set shape: (1409, 19)\n",
            "\n",
            "--- Building Preprocessing Pipelines ---\n",
            "\n",
            "Numerical features: ['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges']\n",
            "Categorical features: ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']\n",
            "\n",
            "--- Training and Tuning Logistic Regression Model ---\n",
            "Best parameters for Logistic Regression: {'classifier__C': 0.01, 'classifier__penalty': 'l2'}\n",
            "Best cross-validation accuracy: 0.8048\n",
            "\n",
            "--- Training and Tuning Random Forest Model ---\n",
            "Best parameters for Random Forest: {'classifier__max_depth': 10, 'classifier__n_estimators': 100}\n",
            "Best cross-validation accuracy: 0.7996\n",
            "\n",
            "--- Evaluating Models on the Test Set ---\n",
            "Logistic Regression Test Accuracy: 0.7984\n",
            "Logistic Regression Test F1-Score: 0.5723\n",
            "\n",
            "Random Forest Test Accuracy: 0.8027\n",
            "Random Forest Test F1-Score: 0.5875\n",
            "\n",
            "--- Final Model Exported ---\n",
            "The trained Logistic Regression pipeline has been saved to 'churn_pipeline.joblib'.\n",
            "\n",
            "--- Example of Loading and Using the Pipeline ---\n",
            "Sample Data:\n",
            "    gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
            "437   Male              0     Yes        Yes      72          Yes   \n",
            "\n",
            "    MultipleLines InternetService OnlineSecurity OnlineBackup  \\\n",
            "437           Yes     Fiber optic            Yes          Yes   \n",
            "\n",
            "    DeviceProtection TechSupport StreamingTV StreamingMovies  Contract  \\\n",
            "437              Yes         Yes         Yes             Yes  Two year   \n",
            "\n",
            "    PaperlessBilling            PaymentMethod  MonthlyCharges  TotalCharges  \n",
            "437              Yes  Credit card (automatic)          114.05        8468.2  \n",
            "\n",
            "Prediction (0=No Churn, 1=Churn): 0\n",
            "Prediction Probability ([No Churn, Churn]): [0.94803347 0.05196653]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import joblib\n",
        "\n",
        "# --- 1. Data Loading and Initial Exploration ---\n",
        "\n",
        "# Load the dataset from the provided CSV file\n",
        "# In a real scenario, you would replace 'WA_Fn-UseC_-Telco-Customer-Churn.csv' with your file path.\n",
        "df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
        "\n",
        "print(\"--- Initial Data Overview ---\")\n",
        "print(df.info())\n",
        "print(\"\\n--- First 5 Rows of the Dataset ---\")\n",
        "print(df.head())\n",
        "\n",
        "# --- 2. Data Cleaning and Preprocessing ---\n",
        "\n",
        "print(\"\\n--- Starting Data Cleaning and Preprocessing ---\")\n",
        "\n",
        "# Drop customerID as it is not a useful feature for prediction\n",
        "df = df.drop('customerID', axis=1)\n",
        "\n",
        "# The 'TotalCharges' column is of object type and contains spaces.\n",
        "# Convert it to a numeric type, coercing errors to NaN (Not a Number).\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "\n",
        "# Check for missing values after conversion\n",
        "print(f\"\\nMissing values in TotalCharges after conversion: {df['TotalCharges'].isnull().sum()}\")\n",
        "\n",
        "# Separate features (X) from the target variable (y)\n",
        "X = df.drop('Churn', axis=1)\n",
        "y = df['Churn']\n",
        "\n",
        "# Encode the target variable 'Churn' into numerical format (Yes=1, No=0)\n",
        "y = y.apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"\\nTraining set shape: {X_train.shape}\")\n",
        "print(f\"Testing set shape: {X_test.shape}\")\n",
        "\n",
        "# --- 3. Pipeline Construction ---\n",
        "\n",
        "print(\"\\n--- Building Preprocessing Pipelines ---\")\n",
        "\n",
        "# Identify categorical and numerical feature columns\n",
        "categorical_features = X.select_dtypes(include=['object']).columns\n",
        "numerical_features = X.select_dtypes(include=np.number).columns\n",
        "\n",
        "print(f\"\\nNumerical features: {list(numerical_features)}\")\n",
        "print(f\"Categorical features: {list(categorical_features)}\")\n",
        "\n",
        "# Create a preprocessing pipeline for numerical data\n",
        "# This will fill missing values with the median and then scale the data\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Create a preprocessing pipeline for categorical data\n",
        "# This will fill missing values with the most frequent value and apply one-hot encoding\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Combine numerical and categorical transformers into a single preprocessor\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# --- 4. Model Training and Hyperparameter Tuning ---\n",
        "\n",
        "# === Logistic Regression ===\n",
        "print(\"\\n--- Training and Tuning Logistic Regression Model ---\")\n",
        "\n",
        "# Create the full pipeline with the preprocessor and the Logistic Regression model\n",
        "lr_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                              ('classifier', LogisticRegression(solver='liblinear', random_state=42))])\n",
        "\n",
        "# Define the parameter grid for GridSearchCV\n",
        "param_grid_lr = {\n",
        "    'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'classifier__penalty': ['l1', 'l2']\n",
        "}\n",
        "\n",
        "# Instantiate and fit GridSearchCV\n",
        "grid_search_lr = GridSearchCV(lr_pipeline, param_grid_lr, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search_lr.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters for Logistic Regression: {grid_search_lr.best_params_}\")\n",
        "print(f\"Best cross-validation accuracy: {grid_search_lr.best_score_:.4f}\")\n",
        "\n",
        "# === Random Forest ===\n",
        "print(\"\\n--- Training and Tuning Random Forest Model ---\")\n",
        "\n",
        "# Create the full pipeline with the preprocessor and the Random Forest model\n",
        "rf_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                              ('classifier', RandomForestClassifier(random_state=42))])\n",
        "\n",
        "# Define a smaller parameter grid for efficiency in this example\n",
        "param_grid_rf = {\n",
        "    'classifier__n_estimators': [100, 200],\n",
        "    'classifier__max_depth': [10, 20, None]\n",
        "}\n",
        "\n",
        "# Instantiate and fit GridSearchCV\n",
        "grid_search_rf = GridSearchCV(rf_pipeline, param_grid_rf, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search_rf.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters for Random Forest: {grid_search_rf.best_params_}\")\n",
        "print(f\"Best cross-validation accuracy: {grid_search_rf.best_score_:.4f}\")\n",
        "\n",
        "\n",
        "# --- 5. Model Evaluation ---\n",
        "\n",
        "print(\"\\n--- Evaluating Models on the Test Set ---\")\n",
        "\n",
        "# Evaluate Logistic Regression\n",
        "lr_best_model = grid_search_lr.best_estimator_\n",
        "y_pred_lr = lr_best_model.predict(X_test)\n",
        "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "f1_lr = f1_score(y_test, y_pred_lr)\n",
        "\n",
        "print(f\"Logistic Regression Test Accuracy: {accuracy_lr:.4f}\")\n",
        "print(f\"Logistic Regression Test F1-Score: {f1_lr:.4f}\")\n",
        "\n",
        "# Evaluate Random Forest\n",
        "rf_best_model = grid_search_rf.best_estimator_\n",
        "y_pred_rf = rf_best_model.predict(X_test)\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "f1_rf = f1_score(y_test, y_pred_rf)\n",
        "\n",
        "print(f\"\\nRandom Forest Test Accuracy: {accuracy_rf:.4f}\")\n",
        "print(f\"Random Forest Test F1-Score: {f1_rf:.4f}\")\n",
        "\n",
        "\n",
        "# --- 6. Exporting the Final Pipeline ---\n",
        "\n",
        "# Based on the evaluation, Logistic Regression performed slightly better on accuracy and F1-score.\n",
        "# We will select it as our final model.\n",
        "final_pipeline = grid_search_lr.best_estimator_\n",
        "\n",
        "# Export the final trained pipeline to a file\n",
        "pipeline_filename = 'churn_pipeline.joblib'\n",
        "joblib.dump(final_pipeline, pipeline_filename)\n",
        "\n",
        "print(f\"\\n--- Final Model Exported ---\")\n",
        "print(f\"The trained Logistic Regression pipeline has been saved to '{pipeline_filename}'.\")\n",
        "\n",
        "# Example of how to load and use the pipeline\n",
        "print(\"\\n--- Example of Loading and Using the Pipeline ---\")\n",
        "loaded_pipeline = joblib.load(pipeline_filename)\n",
        "\n",
        "# Create a sample data point for prediction\n",
        "sample_data = X_test.iloc[0:1]\n",
        "prediction = loaded_pipeline.predict(sample_data)\n",
        "prediction_proba = loaded_pipeline.predict_proba(sample_data)\n",
        "\n",
        "print(f\"Sample Data:\\n{sample_data}\")\n",
        "print(f\"\\nPrediction (0=No Churn, 1=Churn): {prediction[0]}\")\n",
        "print(f\"Prediction Probability ([No Churn, Churn]): {prediction_proba[0]}\")"
      ]
    }
  ]
}